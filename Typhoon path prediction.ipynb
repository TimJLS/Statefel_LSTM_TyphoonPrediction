{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pygeohash as pgh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '1987-2016.kml'\n",
    "# read file\n",
    "ty_name=[]\n",
    "intensity=[]\n",
    "mslp=[]\n",
    "max_int=[]\n",
    "min_slp=[]\n",
    "timesteps=[]\n",
    "lon=[]\n",
    "lat=[]\n",
    "ty_data=np.ndarray(shape = (0,1))\n",
    "z = np.zeros((0,1))\n",
    "import lxml.etree as etree\n",
    "import re\n",
    "parser = etree.XMLParser(strip_cdata=False)\n",
    "tree = etree.parse(file_path, parser=parser)\n",
    "#print(etree.tostring(tree, xml_declaration=True))\n",
    "#print(tree.xpath('//kml:Placemark/kml:TimeSpan/text()', namespaces={\"kml\":\"http://www.opengis.net/kml/2.2\"}))\n",
    "nmsp = '{http://www.opengis.net/kml/2.2}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "### walk through history typhoon file ###\n",
    "for fd in tree.iterfind('/{0}Document/{0}Folder/{0}Folder/{0}Folder'.format(nmsp)):\n",
    "    temp = fd.find('{0}Placemark/{0}name'.format(nmsp)).text\n",
    "    ty_name.append(temp)\n",
    "    count=0\n",
    "    ## feature extraction ##\n",
    "    for dscp in fd.iterfind('{0}Placemark'.format(nmsp)):\n",
    "        #print(dscp.find('{0}description'.format(nmsp)).text)\n",
    "        dscript = dscp.find('{0}description'.format(nmsp)).text\n",
    "        dscript = re.split(r'<[^>]+>|[\\s\\n\\t]', dscript)\n",
    "        temp_info= np.array([ele for ele in dscript if len(ele)>0])\n",
    "        #print(len(temp_info))\n",
    "        if len(temp_info) == 26:\n",
    "            temp_info=np.append(temp_info,count)\n",
    "            timesteps=np.append(timesteps,count)\n",
    "            intensity=np.append(intensity,[temp_info[13]])\n",
    "            mslp=np.append(mslp,[temp_info[16]])\n",
    "            max_int=np.append(max_int,[temp_info[20]])\n",
    "            min_slp=np.append(min_slp,[temp_info[24]])\n",
    "            count+=1\n",
    "        elif len(temp_info) == 30:\n",
    "            timesteps=np.append(timesteps,count)\n",
    "            intensity=np.append(intensity,[temp_info[17]])\n",
    "            mslp=np.append(mslp,[temp_info[20]])\n",
    "            max_int=np.append(max_int,[temp_info[24]])\n",
    "            min_slp=np.append(min_slp,[temp_info[28]])\n",
    "            count+=1\n",
    "        elif len(temp_info) == 33:\n",
    "            timesteps=np.append(timesteps,count)\n",
    "            intensity=np.append(intensity,[temp_info[17]])\n",
    "            mslp=np.append(mslp,[temp_info[23]])\n",
    "            max_int=np.append(max_int,[temp_info[27]])\n",
    "            min_slp=np.append(min_slp,[temp_info[31]])\n",
    "            count+=1\n",
    "        elif len(temp_info) == 35:\n",
    "            timesteps=np.append(timesteps,count)\n",
    "            intensity=np.append(intensity,[temp_info[20]])\n",
    "            mslp=np.append(mslp,[temp_info[25]])\n",
    "            max_int=np.append(max_int,[temp_info[29]])\n",
    "            min_slp=np.append(min_slp,[temp_info[33]])\n",
    "            count+=1\n",
    "    for i in range(count,105):\n",
    "        timesteps=np.append(timesteps,[i], axis=0)\n",
    "        intensity= np.append(intensity, [0], axis = 0)\n",
    "        mslp= np.append(mslp, [0], axis = 0)\n",
    "        max_int= np.append(max_int, [0], axis = 0)\n",
    "        min_slp= np.append(min_slp, [0], axis = 0)\n",
    "        count+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Geogaphic coordinate feature extraction ###\n",
    "lon=[]\n",
    "lat=[]\n",
    "for fd in tree.iterfind('/{0}Document/{0}Folder/{0}Folder/{0}Folder'.format(nmsp)):\n",
    "    count=0\n",
    "    for coor in fd.iterfind('{0}Placemark/{0}Point'.format(nmsp)):\n",
    "        geocoor = coor.find('{0}coordinates'.format(nmsp)).text\n",
    "        lontitude,latitude,_ = geocoor.split(',')\n",
    "        lon = np.append(lon,lontitude)\n",
    "        lat = np.append(lat,latitude)\n",
    "        count+=1\n",
    "    for i in range(count,105):\n",
    "        lon = np.append(lon,lon[-1])\n",
    "        lat = np.append(lat,lat[-1])\n",
    "    #print(len(lon))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95340, 95340, 95340)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize, MinMaxScaler, StandardScaler\n",
    "\n",
    "standard = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "minmax = MinMaxScaler(copy=True, feature_range=(0, 1))\n",
    "\n",
    "'''scaler = scaler.fit_transform(df)\n",
    "scaler = scaler.fit_transform(df)\n",
    "scaled_X = scaler.transform(df['Intensity','MSLP','Max Intensity','Minimum SLP'])\n",
    "\n",
    "inverted_X = scaler.inverse_transform(scaled_X)\n",
    "#arr = arr.reshape(arr.shape[0], 1, arr.shape[1])\n",
    "\n",
    "train_x = df\n",
    "train_y = df'''\n",
    "#mslp = mslp.reshape(-1,1)\n",
    "#standard = standard.fit_transform(mslp)\n",
    "\n",
    "'''plt.figure(figsize=(20,5))\n",
    "plt.hist(standard)'''\n",
    "len(lon),len(intensity),len(mslp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  to pandas Dataframe\n",
    "#data = {'Max Intensity':max_int,'Minimum SLP':min_slp}\n",
    "data = {'lon':lon,'lat':lat,'Intensity':intensity,'MSLP':mslp,'Max Intensity':max_int,'Minimum SLP':min_slp}\n",
    "df = pd.DataFrame(data=data)\n",
    "df = df.apply(pd.to_numeric,downcast='float')\n",
    "for i,ele in enumerate(df['lon']):\n",
    "    gh = pgh.encode(df['lon'][i],df['lat'][i],precision=4)\n",
    "    df.loc[i,'geohash'] = gh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x72c99cca90>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "data = df.corr()\n",
    "sns.heatmap(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from keras.models import load_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:,:], train[:,:]\n",
    "    X = train.reshape(96248, 1, train.shape[1])\n",
    "    \n",
    "    \n",
    "    RMSprop = optimizers.RMSprop(lr=0.001, rho=0.9, decay=0.0, clipvalue=0.1)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(7))\n",
    "    model.compile(loss='mse', optimizer=RMSprop, metrics=['acc'])\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    for i in range(0, 96248, 106):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False,validation_split=0.1,callbacks=[es])\n",
    "        model.reset_states()\n",
    "    model.save('lstm_RMSprop.h5')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86623 samples, validate on 9625 samples\n",
      "Epoch 1/1\n",
      "86623/86623 [==============================] - 211s 2ms/step - loss: 0.2495 - acc: 0.8020 - val_loss: 0.1404 - val_acc: 0.7418\n",
      "Train on 86623 samples, validate on 9625 samples\n",
      "Epoch 1/1\n",
      "86623/86623 [==============================] - 242s 3ms/step - loss: 0.2774 - acc: 0.8017 - val_loss: 0.1564 - val_acc: 0.7538\n",
      "Train on 86623 samples, validate on 9625 samples\n",
      "Epoch 1/1\n",
      "86623/86623 [==============================] - 243s 3ms/step - loss: 0.2599 - acc: 0.7845 - val_loss: 0.1636 - val_acc: 0.7624\n",
      "Train on 86623 samples, validate on 9625 samples\n",
      "Epoch 1/1\n",
      "86623/86623 [==============================] - 198s 2ms/step - loss: 0.2609 - acc: 0.7746 - val_loss: 0.2043 - val_acc: 0.6859\n",
      "Train on 86623 samples, validate on 9625 samples\n",
      "Epoch 1/1\n",
      "86623/86623 [==============================] - 192s 2ms/step - loss: 0.2718 - acc: 0.7530 - val_loss: 0.2054 - val_acc: 0.7116\n",
      "Train on 86623 samples, validate on 9625 samples\n",
      "Epoch 1/1\n",
      "86623/86623 [==============================] - 193s 2ms/step - loss: 0.2707 - acc: 0.7594 - val_loss: 0.2146 - val_acc: 0.7329\n",
      "Train on 86623 samples, validate on 9625 samples\n",
      "Epoch 1/1\n",
      "86623/86623 [==============================] - 188s 2ms/step - loss: 0.2937 - acc: 0.7512 - val_loss: 0.2045 - val_acc: 0.7626\n",
      "Train on 86623 samples, validate on 9625 samples\n",
      "Epoch 1/1\n",
      "86623/86623 [==============================] - 188s 2ms/step - loss: 0.3452 - acc: 0.7359 - val_loss: 0.2645 - val_acc: 0.7387\n",
      "Train on 86623 samples, validate on 9625 samples\n",
      "Epoch 1/1\n",
      "86623/86623 [==============================] - 198s 2ms/step - loss: 0.3940 - acc: 0.7264 - val_loss: 0.1857 - val_acc: 0.7046\n",
      "Train on 86623 samples, validate on 9625 samples\n",
      "Epoch 1/1\n",
      "86623/86623 [==============================] - 197s 2ms/step - loss: 0.2884 - acc: 0.7482 - val_loss: 0.1668 - val_acc: 0.6982\n",
      "Train on 86623 samples, validate on 9625 samples\n",
      "Epoch 1/1\n",
      "52544/86623 [=================>............] - ETA: 1:12 - loss: 0.3820 - acc: 0.7286"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-2265c8771819>\u001b[0m in \u001b[0;36mfit_lstm\u001b[1;34m(train, batch_size, nb_epoch, neurons)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m96248\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m106\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lstm_RMSprop.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1712\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1239\u001b[0m                         \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1241\u001b[1;33m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[0;32m    117\u001b[0m            (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1)):\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[1;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[0;32m   4117\u001b[0m     \"\"\"\n\u001b[0;32m   4118\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[1;32m-> 4119\u001b[1;33m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[0;32m   4120\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4121\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[1;34m(a, func, **kwargs)\u001b[0m\n\u001b[0;32m   4031\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4033\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4034\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_median\u001b[1;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[0;32m   4150\u001b[0m             \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4152\u001b[1;33m         \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4154\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mpartition\u001b[1;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[0;32m    662\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    665\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit_lstm(scaled_X, 1, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('lstm_RMSprop.h5')\n",
    "train_reshaped = scaled_X.reshape(1800, 1, 11)\n",
    "a = model.predict(train_reshaped, batch_size=1)\n",
    "inversed_X = scaler.inverse_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(inversed_X[:,0])\n",
    "plt.plot(arr[:,0])\n",
    "plt.xlim([0,900])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns train, inference_encoder and inference_decoder models\n",
    "def define_models(n_input, n_output, n_units):\n",
    "    # define training encoder\n",
    "    encoder_inputs = Input(shape=(None, n_input))\n",
    "    encoder = LSTM(n_units, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    # define training decoder\n",
    "    decoder_inputs = Input(shape=(None, n_output))\n",
    "    decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(n_output, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    # define inference encoder\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    # define inference decoder\n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "    decoder_state_input_c = Input(shape=(n_units,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "    # return all models\n",
    "    return model, encoder_model, decoder_model\n",
    "\n",
    "def fit_seq2seq(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:,:], train[:,:]\n",
    "    X = train.reshape(train.shape[0], 1, train.shape[1])\n",
    "    y = train.reshape(train.shape[0], 1, train.shape[1])\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True, return_sequences=True))\n",
    "    model.add(Dense(11, activation=\"relu\"))\n",
    "    model.add(LSTM(11, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(units=11, \n",
    "                                    activation=\"softmax\")))\n",
    "    model.compile(loss='mae', optimizer='adam', metrics=['acc'])\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    for i in range(0, 1800, 60):\n",
    "        model.fit(X, y, epochs=100, batch_size=batch_size, verbose=1, shuffle=False,validation_split=0.1,callbacks=[es])\n",
    "        model.reset_states()\n",
    "    model.save('lstm_seq2seq.h5')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_seq2seq(scaled_X, 1, 10, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('lstm_seq2seq.h5')\n",
    "train_reshaped = scaled_X.reshape(1800, 1, 11)\n",
    "a = model.predict(train_reshaped, batch_size=1)\n",
    "inversed_X = scaler.inverse_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inversed_X[0:60,0,0],train_x[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(inversed_X[60:360,0,3])\n",
    "plt.plot(arr[:,3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=train_x[:,0,0]\n",
    "hidden_size=11\n",
    "max_out_seq_len=train_x[0,:,0]\n",
    "output_size=train_x[:,0,0]\n",
    "def build_model(input_size, max_out_seq_len, hidden_size):\n",
    "    RMSprop = optimizers.RMSprop(lr=0.001, rho=0.9, decay=0.0, clipvalue=0.1)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(input_shape=(60,11),\n",
    "                   return_sequences=True,\n",
    "                   units=30))\n",
    "    model.add(Dense(1024, activation=\"relu\"))\n",
    "    \n",
    "    model.add(LSTM(hidden_size, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(units=11, \n",
    "                                    activation=\"softmax\")))\n",
    "    model.compile(loss=\"mse\", optimizer=RMSprop, metrics=['acc'])\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, x, y):\n",
    "    \n",
    "    model = build_model(input_size, max_out_seq_len, hidden_size)\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    model.fit(x, y, \n",
    "              validation_split=0.1,\n",
    "              epochs=epochs,\n",
    "              callbacks=[es])\n",
    "    for i in range(0, 1800, 60):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False,validation_split=0.1)\n",
    "        model.reset_states()\n",
    "    model.save('lstm.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(1000, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = int(len(train_x)/10)\n",
    "test_x = arr[:indices,0:5]\n",
    "test_y = arr[:indices,0:5]\n",
    "scores = model.evaluate(arr[:,0:5,:], arr[:,0:5,:])\n",
    "predictions = model.predict(test_x)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def normalize(train):\n",
    "    \n",
    "    train_norm = train.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "    return train_norm'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def buildTrain(train, pastDay=5, futureDay=5):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(0,train.shape[0]-futureDay-pastDay,5):\n",
    "        X_train.append(np.array(train.iloc[i:i+pastDay]))\n",
    "        Y_train.append(np.array(train.iloc[i+pastDay:i+pastDay+futureDay]))\n",
    "    X_train = np.array(X_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    return X_train, Y_train'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def splitData(X,Y,rate):\n",
    "    X_train = X[int(X.shape[0]*rate):]\n",
    "    Y_train = Y[int(Y.shape[0]*rate):]\n",
    "    X_val = X[:int(X.shape[0]*rate)]\n",
    "    Y_val = Y[:int(Y.shape[0]*rate)]\n",
    "    return X_train, Y_train, X_val, Y_val'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "# Normalization\n",
    "train_norm = normalize(train_x)\n",
    "\n",
    "# build Data, use last 60 timesteps to predict next 60 timesteps\n",
    "X_train, Y_train = buildTrain(train_norm, 5, 5)\n",
    "\n",
    "\n",
    "# shuffle the data, and random seed is 10\n",
    "X_train, Y_train = shuffle(X_train, Y_train)\n",
    "\n",
    "# split training data and validation data\n",
    "X_train, Y_train, X_val, Y_val = splitData(X_train, Y_train, 0.1)\n",
    "\n",
    "\n",
    "model = buildManyToManyModel(X_train.shape)\n",
    "callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
    "model.fit(X_train, Y_train, epochs=1000, batch_size=60, validation_data=(X_val, Y_val), callbacks=[callback])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('2016.geojson')\n",
    "train_dir = \"train\"\n",
    "test_dir = 'test'\n",
    "file=[]\n",
    "time_count=[]\n",
    "gdf_train = pd.DataFrame()\n",
    "gdf_test = pd.DataFrame()\n",
    "def ty_info(typhoon):\n",
    "    ###進行資料的初步處理###\n",
    "    for index, row in typhoon[['geometry']].iterrows():\n",
    "        if typhoon['geometry'][index].geom_type == 'LineString':            \n",
    "            typhoon = typhoon.drop([index])            \n",
    "    typhoon.rename(columns={'MSLP ':'MSLP','Development State ':'Developmant State',\n",
    "                        'Maximum Intensity ':'Maximum Intensity(knots)', 'DTG ':'Date Time Group(DTG)',\n",
    "                        'LAT ':'LAT','LON ':'LON',\n",
    "                        'Intensity ':'Intensity','Minimum SLP ':'central sea level pressure (mb)'}, inplace = True)\n",
    "    typhoon = typhoon.to_xarray()\n",
    "    typhoon = typhoon.to_dataframe()\n",
    "    typhoon['MSLP'] = typhoon['MSLP'].str.replace(' mb','')\n",
    "    typhoon['Maximum Intensity(knots)'] = typhoon['Maximum Intensity(knots)'].str.replace(' kts','')\n",
    "    typhoon['central sea level pressure (mb)'] = typhoon['central sea level pressure (mb)'].str.replace(' mb','')\n",
    "    typhoon['Year'], typhoon['Month'], typhoon['Date'] = typhoon['begin'].str.split('-',2).str\n",
    "    typhoon['Year'] = typhoon['Year']\n",
    "    typhoon['Month'] = typhoon['Month']\n",
    "    \n",
    "    typhoon = typhoon.drop(columns=['description','begin','end','tessellate','Date Time Group(DTG)','Best Track Duration ','Date'])\n",
    "    \n",
    "    ###轉換資料格式###\n",
    "    typhoon[['MSLP','Maximum Intensity(knots)','LAT','LON','Intensity','central sea level pressure (mb)','Year','Month']] = typhoon[['MSLP','Maximum Intensity(knots)','LAT','LON','Intensity','central sea level pressure (mb)','Year','Month']].apply(pd.to_numeric,errors='coerce',downcast='float')\n",
    "    return typhoon\n",
    "\n",
    "gdf['name1'], gdf['name2'], gdf['name3'] = gdf['description'].str.split('\\n\\t\\t', 2).str\n",
    "list(gdf['name1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀檔(index, name, ....)並完成資料格式整理\n",
    "\n",
    "**表示方法**:單純以數字表示呢還是矩陣(ex:May:[0,0,0,0,1,0,0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分割原始資料成Train, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(time_count),len(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(dir, gdf):\n",
    "    for root, dirs, files in os.walk(dir, topdown=False):\n",
    "        \n",
    "        for name in files:\n",
    "            temp = gpd.read_file(os.path.join(root,name))\n",
    "        \n",
    "            time_count.append(len(temp.index))\n",
    "            file.append(name.replace('.geojson',''))\n",
    "\n",
    "        \n",
    "            temp = ty_info(temp)\n",
    "            #global gdf\n",
    "            gdf = gdf.append(temp)\n",
    "        \n",
    "            gdf = gpd.GeoDataFrame(gdf, crs={'init': 'epsg:4326'}, geometry=temp['geometry'])\n",
    "    return gdf\n",
    "#load_file(train_dir, gdf_train)\n",
    "load_file(test_dir, gdf_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
